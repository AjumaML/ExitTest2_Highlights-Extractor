{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c741a9-84ca-42cf-b3a3-e6dfdb6b1fbc",
   "metadata": {},
   "source": [
    "### Creating Model for Classifying Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fadbaaa4-088c-49a0-b0d8-51a0aa891e3c",
   "metadata": {
    "id": "fadbaaa4-088c-49a0-b0d8-51a0aa891e3c"
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b48c72b-5b3e-4768-94d3-e3ddc1538cfd",
   "metadata": {
    "id": "5b48c72b-5b3e-4768-94d3-e3ddc1538cfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-15 19:47:56.610576: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d40b63fd-5143-4125-8c06-2022a5b4c01f",
   "metadata": {
    "id": "d40b63fd-5143-4125-8c06-2022a5b4c01f"
   },
   "outputs": [],
   "source": [
    "imagePaths = list(paths.list_images('Reaction_Dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4apSAMRNkjFv",
   "metadata": {
    "id": "4apSAMRNkjFv"
   },
   "outputs": [],
   "source": [
    "# Extracting Data and Label\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "IMG_SIZE = 224\n",
    "CHANNELS = 3\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "  label = imagePath.split(os.path.sep)[-2]\n",
    "  image = load_img(imagePath, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "  image = img_to_array(image)\n",
    "  image = image/255\n",
    "  \n",
    "\n",
    "  data.append(image)\n",
    "  labels.append(label)\n",
    "\n",
    "\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pMLno9OsqU2G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMLno9OsqU2G",
    "outputId": "0d48914e-eb34-4a9e-c7d9-449d41a06a19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['.ipynb_checkpoints', 'Happy', 'Loss'], dtype='<U18'),\n",
       " array([   1, 2844, 1095]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Labels\n",
    "\n",
    "np. unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "X3zvAnUuq3iJ",
   "metadata": {
    "id": "X3zvAnUuq3iJ"
   },
   "outputs": [],
   "source": [
    "#Encoding Labels\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "F0d1QN9oq8zf",
   "metadata": {
    "id": "F0d1QN9oq8zf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4CP5b1dsrAPG",
   "metadata": {
    "id": "4CP5b1dsrAPG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\ttest_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mL-calGYrD_t",
   "metadata": {
    "id": "mL-calGYrD_t"
   },
   "outputs": [],
   "source": [
    "#ResNet50 is a big network with 50 layers\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "X8Lh7lQqrIdu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8Lh7lQqrIdu",
    "outputId": "7501f949-131b-4ab0-afe5-5111eb4569a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-15 15:53:57.940759: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_layer = ResNet50V2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(IMG_SIZE,IMG_SIZE,CHANNELS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "Rep1dsjSrLv6",
   "metadata": {
    "id": "Rep1dsjSrLv6"
   },
   "outputs": [],
   "source": [
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "VPPVOfKmrSHi",
   "metadata": {
    "id": "VPPVOfKmrSHi"
   },
   "outputs": [],
   "source": [
    "#Model Creation\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(feature_extractor_layer)\n",
    "model.add(layers.Flatten(name=\"flatten\"))\n",
    "model.add(layers.Dense(1024, activation='relu', name='hidden_layer'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='softmax', name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "XCV4IZU6rU2v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XCV4IZU6rU2v",
    "outputId": "ce5f37e2-87ae-4878-c393-c7faf84131c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 7, 7, 2048)        23564800  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " hidden_layer (Dense)        (None, 1024)              102761472 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,328,322\n",
      "Trainable params: 102,763,522\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "m4OjUfsNraVk",
   "metadata": {
    "id": "m4OjUfsNraVk"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "  loss=\"categorical_crossentropy\",\n",
    "  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "YAdWdOVQrbwf",
   "metadata": {
    "id": "YAdWdOVQrbwf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6WmnWyhredd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6WmnWyhredd",
    "outputId": "eadb65ef-1b3f-4049-e3b8-e575972fcf81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "99/99 [==============================] - 262s 3s/step - loss: 1.1470 - accuracy: 0.6604 - val_loss: 0.6592 - val_accuracy: 0.7259\n",
      "Epoch 2/10\n",
      "99/99 [==============================] - 267s 3s/step - loss: 0.8030 - accuracy: 0.7080 - val_loss: 0.6331 - val_accuracy: 0.7538\n",
      "Epoch 3/10\n",
      "99/99 [==============================] - 265s 3s/step - loss: 0.6759 - accuracy: 0.7312 - val_loss: 0.5728 - val_accuracy: 0.7525\n",
      "Epoch 4/10\n",
      "99/99 [==============================] - 272s 3s/step - loss: 0.6399 - accuracy: 0.7274 - val_loss: 0.5541 - val_accuracy: 0.7475\n",
      "Epoch 5/10\n",
      "99/99 [==============================] - 280s 3s/step - loss: 0.5654 - accuracy: 0.7547 - val_loss: 0.5152 - val_accuracy: 0.7525\n",
      "Epoch 6/10\n",
      "99/99 [==============================] - 270s 3s/step - loss: 0.5403 - accuracy: 0.7544 - val_loss: 0.5227 - val_accuracy: 0.7437\n",
      "Epoch 7/10\n",
      "99/99 [==============================] - 272s 3s/step - loss: 0.5074 - accuracy: 0.7664 - val_loss: 0.4846 - val_accuracy: 0.7589\n",
      "Epoch 8/10\n",
      "99/99 [==============================] - 265s 3s/step - loss: 0.5140 - accuracy: 0.7636 - val_loss: 0.4864 - val_accuracy: 0.7538\n",
      "Epoch 9/10\n",
      "99/99 [==============================] - 257s 3s/step - loss: 0.4915 - accuracy: 0.7693 - val_loss: 0.4770 - val_accuracy: 0.7640\n",
      "Epoch 10/10\n",
      "99/99 [==============================] - 254s 3s/step - loss: 0.4713 - accuracy: 0.7766 - val_loss: 0.4660 - val_accuracy: 0.7792\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(aug.flow(trainX, trainY),\n",
    "\t                  validation_data=(testX, testY),\n",
    "\t                  epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6AY3Ezmcr2oB",
   "metadata": {
    "id": "6AY3Ezmcr2oB"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "MrJmRNTNr7qJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrJmRNTNr7qJ",
    "outputId": "c133f05e-26ca-469b-c5c8-c7c67ea62013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 43s 2s/step\n"
     ]
    }
   ],
   "source": [
    "predIdxs = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "zun9WLLAr-lZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zun9WLLAr-lZ",
    "outputId": "3b12708d-2303-4084-9a31-0f4a21bd52ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04677653, 0.9532235 ], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predIdxs[501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "HWlt70cTsDwu",
   "metadata": {
    "id": "HWlt70cTsDwu"
   },
   "outputs": [],
   "source": [
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1znJBqoNsHUX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1znJBqoNsHUX",
    "outputId": "123087cf-c678-4936-a05b-9f926a930968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.83      0.88      0.85       569\n",
      "        Loss       0.62      0.52      0.57       219\n",
      "\n",
      "    accuracy                           0.78       788\n",
      "   macro avg       0.72      0.70      0.71       788\n",
      "weighted avg       0.77      0.78      0.77       788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testY.argmax(axis=1), predIdxs,target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf9529e3-dd6b-4a8d-94b1-e20e471f0945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model for classifying moments\n",
    "\n",
    "model.save('Model_Moments_CNN.h5', save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8fdb785d-9b19-4f10-b9e5-fa865e361930",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('Model_Moments_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e27dcca-989a-4981-bc4d-791a2176200f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
